{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5505af4",
   "metadata": {},
   "source": [
    "# PRÁCTICA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4a760",
   "metadata": {},
   "source": [
    "Lucía Pérez González, Manuel Ramallo Blanco, Alexandre Lorenzo Martínez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b54141",
   "metadata": {},
   "source": [
    "## 1 - Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe9e71",
   "metadata": {},
   "source": [
    "### 1.1 - Eliminación de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b5f96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir datasets\n",
    "import pandas as pd\n",
    "\n",
    "df_vino = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Eliminación de duplicados, ignorado quality\n",
    "cols = df_vino.columns.drop('quality')\n",
    "df_vino = df_vino.drop_duplicates(subset=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0834f",
   "metadata": {},
   "source": [
    "### 1.2 - Binarización de la calidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f3f78ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar_vino(valor): \n",
    "    if valor < 7: \n",
    "        return \"baja calidad\" \n",
    "    elif valor >= 7: \n",
    "        return \"alta calidad\" \n",
    "df_vino['calidad'] = df_vino['quality'].apply(clasificar_vino) \n",
    "df_vino = df_vino.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ae80f",
   "metadata": {},
   "source": [
    "### 1.3 - Gestión de valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de filas con 0, 1, 2, ... atípicos (IQR + negativos):\n",
      "num atipicos\n",
      "0    1829\n",
      "1    1142\n",
      "2     516\n",
      "3     184\n",
      "4      50\n",
      "5       8\n",
      "6       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Deteccion de valores atipicos\n",
    "\n",
    "def detectar_atipicos(df_train, df_val, cols_diana):\n",
    "    for col in cols_diana:\n",
    "\n",
    "        # Calculamos IQR y límites\n",
    "        Q1 = df_train[col].quantile(0.25)\n",
    "        Q3 = df_train[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 6 * IQR\n",
    "        upper = Q3 + 6 * IQR\n",
    "        \n",
    "        # Declaramos condición de atípico y registramos sus posiciones\n",
    "        cond_iqr = (df_train[col] < lower) | (df_train[col] > upper)    #OLLO! Nico recomendara ver os casos 1 a 1 \n",
    "        cond_neg = df_train[col] < 0\n",
    "        cond_atipico = cond_iqr | cond_neg\n",
    "\n",
    "\n",
    "        # Incrementamos el contador de atípicos por fila en ambos conjuntos\n",
    "        df_train.loc[cond_atipico, col] = pd.NA\n",
    "        df_val.loc[cond_atipico, col] = pd.NA\n",
    "\n",
    "\n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c7c55f",
   "metadata": {},
   "source": [
    "#### 1.3.11 - Tratamiento de datos atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d19cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_o_imputacion(df_train, df_val, cols_diana, max_atipicos=3, umbral_col=20,  target='calidad'):\n",
    "    # Eliminar filas con 4 o más valores atípicos\n",
    "    # Contamos el número de valores atípicos por fila (NA) y filtramos \n",
    "    df_train = df_train[df_train.isnull().sum(axis=1) < max_atipicos]\n",
    "\n",
    "    # Analisis de valores faltantes por columna\n",
    "    for col in cols_diana:\n",
    "        # Contamos el numero de valores faltantes (NA) en la columna(\n",
    "        num_faltantes = df_train[col].isna().sum()\n",
    "        if num_faltantes/len(df_train) > umbral_col:\n",
    "            df_train = df_train.drop(columns=[col])\n",
    "            df_val = df_val.drop(columns=[col])\n",
    "\n",
    "    # Imputacion de valores: mediana para cada nulo de cada columna\n",
    "    for col in cols_diana:\n",
    "        med = df_train[col].median()\n",
    "        df_train[col] = df_train[col].fillna(med)\n",
    "        df_val[col] = df_val[col].fillna(med)\n",
    "\n",
    "    return df_train, df_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d17c98",
   "metadata": {},
   "source": [
    "#### Normalización y selección de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be145b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def estandarizar_train_test(train_df, test_df, target):\n",
    "    columnas = train_df.drop(columns=[target]).select_dtypes(include=\"number\").columns\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    train_df[columnas] = scaler.fit_transform(train_df[columnas])\n",
    "    test_df[columnas] = scaler.transform(test_df[columnas])\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd31d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características con SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "def seleccion_caracteristicas(df, k, target='calidad'):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    df_fs = df[selected_features.tolist() + [target]]\n",
    "    return df_fs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5187dd",
   "metadata": {},
   "source": [
    "#### Función que empaqueta el preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesado(train_df_pre, valid_df_pre, target='calidad'):\n",
    "    df_train = train_df_pre.copy()\n",
    "    df_val = valid_df_pre.copy()\n",
    "    cols_diana = [c for c in train_df_pre.columns if c not in [target]]\n",
    "    \n",
    "    # Detección de atípicos en train y valid\n",
    "    df_train, df_val = detectar_atipicos(df_train, df_val, cols_diana)\n",
    "\n",
    "    # Tratamiento de atípicos: eliminación o imputación\n",
    "    df_train, df_val = eliminar_o_imputacion(df_train, df_val, cols_diana)\n",
    "\n",
    "    # Normalización de los datos\n",
    "    df_train, df_val = estandarizar_train_test(df_train, df_val, target)\n",
    "\n",
    "    # Selección de características con SelectKBest\n",
    "    df_train = seleccion_caracteristicas(df_train, k=10, target=target)\n",
    "    df_val = df_val[df_train.columns]\n",
    "    return df_train, df_val \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898266ff",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fead309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de entrenamiento\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def nested_cv(df, target='calidad'):\n",
    "    \"\"\"\n",
    "    Validación cruzada anidada:\n",
    "    - exterior: 3 iteraciones (6 pedazos, 4 train, 2 val)\n",
    "    - interior: 4 pedazos (3 train, 1 val)\n",
    "    \n",
    "    Devuelve: diccionario con información de folds\n",
    "    \"\"\"\n",
    "    \n",
    "    # Mezclar el dataset para aleatoriedad\n",
    "    df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    n = len(df_shuffled)\n",
    "    \n",
    "    # Dividir en 6 pedazos iguales (outer)\n",
    "    outer_splits = np.array_split(df_shuffled, 6)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Outer CV\n",
    "    for outer_iter in range(3):\n",
    "        # Elegimos 4 pedazos para train, 2 para val\n",
    "        outer_train_idx = [(outer_iter + i) % 6 for i in range(4)]\n",
    "        outer_valid_idx = [(outer_iter + 4 + i) % 6 for i in range(2)]\n",
    "        \n",
    "        train_outer = pd.concat([outer_splits[i] for i in outer_train_idx])\n",
    "        valid_outer = pd.concat([outer_splits[i] for i in outer_valid_idx])\n",
    "        \n",
    "        # Dividir train_outer en 4 pedazos para inner CV\n",
    "        inner_splits = np.array_split(train_outer.sample(frac=1, random_state=outer_iter), 4)\n",
    "        \n",
    "        inner_results = []\n",
    "        \n",
    "        # Inner CV\n",
    "        for inner_iter in range(4):\n",
    "            inner_valid_pre = inner_splits[inner_iter]\n",
    "            inner_train_pre = pd.concat([s for j, s in enumerate(inner_splits) if j != inner_iter])\n",
    "            \n",
    "            # Preprocesar\n",
    "            df_train, df_val = preprocesado(inner_train_pre, inner_valid_pre, target)\n",
    "            \n",
    "            # --- Aquí va el entrenamiento de los modelos ---\n",
    "\n",
    "            # Guardar info del cada ejecución del fold interno\n",
    "            inner_results.append({\n",
    "                \"inner_iter\": inner_iter,\n",
    "                \"train_rows\": len(df_train),\n",
    "                \"valid_rows\": len(df_val),\n",
    "                # \"score\": score\n",
    "            })\n",
    "        \n",
    "        # Preprocesar outer validation usando train outer\n",
    "        train_outer_proc, valid_outer_proc = preprocesado(train_outer, valid_outer, target)\n",
    "        \n",
    "        # aqui entreno en train_outer_proc el modelo con mejor puntuación del la VC interna y evalúo en valid_outer_proc\n",
    "        \n",
    "\n",
    "        results.append({\n",
    "            \"outer_iter\": outer_iter,\n",
    "            \"train_rows_outer\": len(train_outer_proc),\n",
    "            \"valid_rows_outer\": len(valid_outer_proc),\n",
    "            \"inner_folds\": inner_results,\n",
    "            # \"outer_score\": outer_score\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b050a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
